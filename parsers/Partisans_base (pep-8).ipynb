{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b6c490",
   "metadata": {},
   "source": [
    "# Partisan web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ada3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import ipywidgets\n",
    "import time\n",
    "from multiprocessing import Pool, set_start_method\n",
    "from download_partisans_html import download_partisans_html # Этот файл лежит в репозитории отдельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fe82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Командадля распараллеливания\n",
    "set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2854988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Краулер, сохраняющий html файлы в /links/number.htm\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(30)\n",
    "    numbers_considered = range(23000, 170000) # Задаю диапазон\n",
    "    number_processed = []\n",
    "    for number in tqdm.tqdm(p.imap(download_partisans_html,\n",
    "                                   numbers_considered),\n",
    "                            total=len(numbers_considered)):\n",
    "        number_processed.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаю сегодняшнюю дату\n",
    "today = str(date.today())\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f2886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной парсер для партизан\n",
    "partisans = []\n",
    "links = os.listdir(\"/Users/annalevina/Desktop/links\")\n",
    "z = 1\n",
    "for link in links:\n",
    "    if link == '.DS_Store':\n",
    "        continue\n",
    "    with open(os.path.join('/Users/annalevina/Desktop/links', link)) as f:\n",
    "        soup = BeautifulSoup(f.read()) # Считываю файлы из папки\n",
    "    credentials = {}\n",
    "    name = soup.find(\"h1\", attrs={'class': \"info-book__title\"}).text.strip()\n",
    "    name = name.split(sep=\" \", maxsplit=3)\n",
    "    bio = soup.find(\"ul\", attrs={'class': \"info-book__descr\"}).text\n",
    "    credentials[\"original_link\"] = \"https://partizany.by/partisans/\" + link + \"/\"\n",
    "    credentials[\"id\"] = \"partisans-\" + str(z)\n",
    "    z = z + 1 # Задаю ID для каждого партизана\n",
    "    credentials[\"retrieved_at\"] = today\n",
    "    try:\n",
    "        credentials[\"surname\"] = name[0]\n",
    "    except IndexError:\n",
    "        credentials[\"surname\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"firstname\"] = name[1]\n",
    "    except IndexError:\n",
    "        credentials[\"firstname\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"patronym\"] = name[2]\n",
    "    except IndexError:\n",
    "        credentials[\"patronym\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"fullname\"] = name[0] + \" \" + name[1] + \" \" + name[2]\n",
    "    except IndexError:\n",
    "        credentials[\"fullname\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"birthdate\"] = re.search(r'\\d{4}', bio).group().strip()\n",
    "    except AttributeError:\n",
    "        credentials[\"birthdate\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"birthplace\"] = re.search(r'(?<=Место\\sрождения: \\s).*',\n",
    "                                              bio).group().strip()\n",
    "    except AttributeError:\n",
    "        credentials[\"birthplace\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"nationality\"] = re.search(r'(?<=Национальность:\\s).*',\n",
    "                                               bio).group().strip()\n",
    "    except AttributeError:\n",
    "        credentials[\"nationality\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"award\"] = []\n",
    "        award = soup.find(\"div\", attrs={'class': \"info-book__rewards-list\"})\n",
    "        # Следующим шагом использую цикл, потому что в одной карточке партизана может быть несколько наград\n",
    "        for rewards_item in award.find_all(\"div\", attrs={'class': \"info-book__rewards-item\"}):\n",
    "            credentials[\"award\"].append(rewards_item.find(\"img\")['alt'])\n",
    "    except AttributeError:\n",
    "        credentials[\"award\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"award_nomination\"] = []\n",
    "        presented = soup.find(\"div\", attrs={'class': \"info-book__rewards-inline\"})\n",
    "        # Цикл, потому что нагарад может быть несколько\n",
    "        for item in presented.find_all(\"span\", attrs={'class': \"info-book__rewards-inline-text\"}):\n",
    "            credentials[\"award_nomination\"].append(item.text)\n",
    "    except AttributeError:\n",
    "        credentials[\"award_nomination\"] = \"\"\n",
    "    try:\n",
    "        credentials[\"partisan_time_period\"] = []\n",
    "        credentials[\"partisan_brigade\"] = []\n",
    "        credentials[\"partisan_detachment\"] = []\n",
    "        credentials[\"partisan_position\"] = []\n",
    "        # Каждый партизан может состоять в нескольких формированиях и занимать в них разные должности\n",
    "        formation__list = soup.find(\"div\", attrs={'class': \"formation__list\"})\n",
    "        for formation_item in formation__list.find_all(\"div\", attrs={'class': \"formation__item\"}):\n",
    "            credentials[\"partisan_time_period\"].append(\n",
    "                formation_item.find(\"div\", attrs={'class': \"formation__item-date\"}).text)\n",
    "        for item_descr in formation_item.find_all(\"ul\", attrs={'class': \"formation__item-descr\"}):\n",
    "            help = item_descr.find_all(\"li\")\n",
    "            credentials[\"partisan_brigade\"].append(help[0].find('a').text)\n",
    "            credentials[\"partisan_detachment\"].append(help[1].find('a').text)\n",
    "            credentials[\"partisan_position\"].append(\n",
    "                re.sub(\"^\\nДолжность: \", \"\", help[2].text).strip())\n",
    "    except:\n",
    "        credentials[\"partisan_time_period\"] = \"\"\n",
    "        credentials[\"partisan_brigade\"] = \"\"\n",
    "        credentials[\"partisan_detachment\"] = \"\"\n",
    "        credentials[\"partisan_position\"] = \"\"\n",
    "    partisans.append(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6061917f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Запись в файл\n",
    "with open('partisans.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(partisans, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
