{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import json   \n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    'Accept': '###',\n",
    "    'User-Agent': '###'\n",
    "}\n",
    "\n",
    "\n",
    "def get_html(url, params = ''):\n",
    "    r = requests.get(url, headers = HEADERS, params = params)\n",
    "    return r\n",
    "\n",
    "\n",
    "def extract_simple_table(soup): # простые таблицы (\"Рукоположение / Постриг / Возведение в сан\" и \"Награды\")\n",
    "    values = []\n",
    "    \n",
    "    position = soup.find(\"table\").find_all(\"tr\")\n",
    "    for item in position:\n",
    "        info = dict()\n",
    "        info[\"Дата\"] = item.find('td',class_=\"date\").get_text(strip=True)\n",
    "        info[\"Описание\"] = item.find('td',class_=\"details\").get_text(strip=True)\n",
    "        values.append(info)\n",
    "    return values\n",
    "\n",
    "def extract_table_with_head(soup): # таблицы с заголовками (\"Образование\" и \"Места служения / Должности\")\n",
    "    values = []\n",
    "    keys = soup.find('thead').find_all('th')\n",
    "    lines = soup.find('tbody').find_all('tr')\n",
    "    for line in range(0,len(lines)):\n",
    "        cells = lines[line].find_all('td')\n",
    "        info = dict()\n",
    "        for cell in range(0,len(cells)):\n",
    "            info[keys[cell].get_text(strip=True)] = cells[cell].get_text(strip=True)\n",
    "        values.append(info)\n",
    "    \n",
    "    return values\n",
    "\n",
    "def extract_relations(soup): # таблица \"Родственники\"\n",
    "    values = dict()\n",
    "    items = soup.find_all('li')\n",
    "    for item in items:\n",
    "        if(item.find('strong') is None):\n",
    "            continue\n",
    "        relation = item.find('strong').get_text(strip=True)\n",
    "        name = item.get_text(strip=True).split(relation)[1].strip('—').strip(' ') # разделение по \"—\", так как часто бывает нарушение структуры html\n",
    "        values[relation] = name\n",
    "    return values\n",
    "\n",
    "def extract_text(soup): # \"Другие сведения\"\n",
    "    return soup.find(class_=\"person__text\").get_text(strip = True)\n",
    "\n",
    "def extract_list(soup): # списки (\"Архивные источники\", \"Литература\", \"Сочинения\")\n",
    "    values = []\n",
    "    \n",
    "    for item in soup.find_all(\"li\"):\n",
    "        values.append(item.get_text(strip=True))\n",
    "    \n",
    "    return values\n",
    "\n",
    "def parse_person_block(soup):\n",
    "    key = soup.find(\"h2\").get_text(strip = True)\n",
    "    \n",
    "    values = []\n",
    "    if(key == \"Родственники\"):\n",
    "        values = extract_relations(soup)\n",
    "    elif(key == \"Рукоположение / Постриг / Возведение в сан\"):\n",
    "        values = extract_simple_table(soup)\n",
    "    elif(key == \"Награды\"):\n",
    "        values = extract_simple_table(soup)\n",
    "    elif(soup.find(\"thead\") is not None):\n",
    "        values = extract_table_with_head(soup)\n",
    "    elif(soup.find(class_=\"person__list\") is not None):\n",
    "        values = extract_list(soup)\n",
    "    elif(soup.find(class_=\"person__text\") is not None):\n",
    "        values = extract_text(soup)\n",
    "    \n",
    "    return (key,values)\n",
    "\n",
    "\n",
    "def parse_all_person_blocks(soup,values):    \n",
    "    for block in soup.find_all(\"div\", class_=\"person__block\"):\n",
    "        if(block.find(\"h2\") is None):\n",
    "            continue\n",
    "        (key,value) = parse_person_block(block)\n",
    "        values[key] = value\n",
    "        \n",
    "def parse_person_details(soup,values):\n",
    "    for tr in soup.find(class_='person-detail__info').find_all(\"tr\"):\n",
    "        ths = tr.find_all(\"th\")\n",
    "        tds = tr.find_all(\"td\")\n",
    "        for i in range(0,len(ths)):\n",
    "            values[ths[i].get_text(strip=True)] = tds[i].get_text(strip=True)\n",
    "            \n",
    "def extract_values(soup):\n",
    "    values = dict()\n",
    "    \n",
    "    values['ФИО'] = soup.find('div', class_ = 'person-detail__info').find('h1').get_text(strip = True)\n",
    "    parse_person_details(soup,values)\n",
    "    parse_all_person_blocks(soup,values)\n",
    "    \n",
    "    return values \n",
    "\n",
    "    \n",
    "def get_content(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return extract_values(soup)\n",
    "    \n",
    "\n",
    "def parse_person(n):\n",
    "    return get_content(get_html('https://www.pravoslavnoe-duhovenstvo.ru/person/' + str(n)).text)\n",
    "\n",
    "html = get_html(URL)\n",
    "content = get_content(html.text)\n"
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = list()\n",
    "\n",
    "for i in range(,):\n",
    "    \n",
    "    try: # напечатает, получилось ли извлечь страницу\n",
    "        print(i)\n",
    "        parsed.append(parse_person(i))\n",
    "    except Exception as e: \n",
    "        print(str(e))\n",
    "\n",
    "with open('###.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(parsed, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
